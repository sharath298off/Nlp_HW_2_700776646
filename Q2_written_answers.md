# CS5760 Homework 2
# Student Name: Sharath chandra seriyala
# 700-700776646
## Q2 â€“ Harms of Classification 

1. Representational Harm

Representational harm occurs when a classification system reinforces negative stereotypes or unfair portrayals of certain social groups.

Kiritchenko & Mohammad (2018) demonstrated this harm by showing that many sentiment analysis lexicons associate words related to women and minority groups with more negative sentiment compared to other groups. As a result, systems built using these resources may produce biased predictions.

2. Risk of Censorship in Toxicity Classification

One major risk is that toxicity classifiers may incorrectly label non-toxic language used by marginalized communities as toxic. This can lead to over-censorship and silence those communities, preventing them from expressing themselves online.

3. Why Classifiers Perform Worse on African American English or Indian English

Most NLP training data is dominated by Standard American English. Because dialectal varieties such as African American English and Indian English are underrepresented, models fail to learn their linguistic patterns, leading to higher error rates.
